---
title: "p8105_hw6_wm2460"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1
To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r p1_plot}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 
The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 


## Problem 2

### Tidying the dataset
```{r message=FALSE}
homicides_df = read_csv("./data/homicide-data.csv")

homicides_new = homicides_df %>% 
  janitor::clean_names() %>% 
  mutate(city_state = str_c(city, state, sep = "_")) %>% 
  filter(!city_state %in% c("Dallas_TX", "Phoenix_AZ", "Kansas City_MO", "Tulsa_AL"), 
         victim_race %in% c("Black", "White")) %>% 
  mutate(victim_age = as.numeric(victim_age),
         resolved = as.numeric(disposition == "Closed by arrest"),
         victim_race = fct_relevel(victim_race, "White"),
         victim_sex = fct_relevel(victim_sex, "Female"))

```

### `glm` for Baltimore
```{r glm_baltimore}
baltimore_glm = homicides_new %>% 
  filter(city_state == "Baltimore_MD") %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
  broom::tidy()

baltimore_glm
```

### Adjusted odds ratio for Baltimore
```{r or_baltimore}
baltimore_glm %>% 
  mutate(OR = exp(estimate),
         CI_upper = exp(estimate + 1.96 * std.error),
         CI_lower = exp(estimate - 1.96 * std.error)) %>%
  filter(term == "victim_sexMale") %>%
  select(term, OR, CI_upper, CI_lower) %>% 
  knitr::kable(digits = 3)
```

### `glm` and adjusted odds ratio for all cities
```{r glm_all}
all_glm = homicides_new %>% 
  nest(all_cities = -city_state) %>%
  mutate(models = map(.x = all_cities, ~glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
         results = map(models, broom::tidy)) %>% 
  select(-models, -all_cities) %>% 
  unnest(cols = results) %>% 
  mutate(OR = exp(estimate),
         CI_upper = exp(estimate + 1.96 * std.error),
         CI_lower = exp(estimate - 1.96 * std.error)) %>% 
  filter(term == "victim_sexMale") %>% 
  select(city_state, OR, CI_upper, CI_lower)

all_glm %>% 
  knitr::kable(digits = 3)
```

### Plot for adjusted OR and 95% CI
```{r plot_or}
or_plot = all_glm %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  ylim(0, 4) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

or_plot
```

Comment on the plot:
Here, we can see that New York has the lowest adjusted odds ratio and Albuquerque has the highest adjusted odds ratio. Since many cities have odds ratio below 1, the odds of having a resolved homicide when the victim is male is usually lower than the odds of having a resolved homicide when the victim was female in many cities, after adjusting for victim age and victim race. The 95% CI of Fresno, Stockton, and Albuquerque is much wider than other cities. 


## Problem 3

### Load and clearn
```{r p3_load}
bw_df = read_csv("./data/birthweight.csv")

bw_new = bw_df %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace)) 

sum(is.na(bw_new))
```

Cleaned the dataset and there is no missing data since `sum(is.na(bw_new))` returns 0.

### Model 1
```{r m1}
m1 = lm(bwt ~ wtgain, data = bw_new)

m1_df = bw_new %>% 
  select(bwt, wtgain) %>% 
  modelr::add_residuals(m1) %>% 
  modelr::add_predictions(m1)

m1_df %>% 
  ggplot(aes(x = wtgain, y = resid)) + geom_violin()
```

I picked the variable `wtgain` as the predictor for model 1 and I picked it based on a hypothesized structure for the factors that underly birthweight. It is possible that motherâ€™s weight gain during pregnancy is closely related to baby's birth weight. If the mother gain more weight, perhaps the baby's birth weight is heavier 

The residual plot shows that the residual of `wtgain` is approximately normally distributed and there are not any notable outliers from the residual plot.  

## Model 2 & 3
```{r m2&3}
m2 = lm(bwt ~ blength + gaweeks, data = bw_new)

m3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = bw_new)
```

## Crossvalidation
```{r cv}
bw_cv = crossv_mc(bw_new, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(m1_cv = map(train, ~lm(bwt ~ wtgain, data = .x)),
         m2_cv = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         m3_cv = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_m1 = map2_dbl(m1_cv, test, ~rmse(model = .x, data = .y)),
         rmse_m2 = map2_dbl(m2_cv, test, ~rmse(model = .x, data = .y)), 
         rmse_m3 = map2_dbl(m3_cv, test, ~rmse(model = .x, data = .y)))

bw_cv_plot = bw_cv %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(everything(), 
               names_to = "model",
               values_to = "rmse",
               names_prefix = "rmse_") %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

bw_cv_plot
```

From the violin plot, we can see that model 1 has the highest RMSE and model 3 has the lowest RMSE. Since it is preferable to select the model with the smallest RMSE, model 3 is better comparing to the other two models. 


## End of HW6